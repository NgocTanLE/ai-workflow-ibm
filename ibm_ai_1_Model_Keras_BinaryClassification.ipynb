{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ibm_ai_1_Model_Keras_BinaryClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxYQsf2xk9i3",
        "colab_type": "text"
      },
      "source": [
        "@Ngoc Tan Le\n",
        "\n",
        "---\n",
        "\n",
        "Dimanche 05 Janvier 2019\n",
        "# **Classifying movie reviews: a binary classification example**\n",
        "Two-class classification, or binary classification, may be the most widely applied kind of machine-learning problem. In this example, you’ll learn to classify movie reviews as positive or negative, based on the text content of the reviews.\n",
        "\n",
        "*IMDB dataset*: a set of 50,000 highly polarized reviews from the Internet Movie Database. They’re split into 25,000 reviews for training and 25,000 reviews for testing, each set consisting of 50% negative and 50% positive reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FA_VYNigZ1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# coding: utf-8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6ycPMU10ogx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import logging\n",
        "from functools import wraps\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "COL_NAME_METHOD_NAME = \"Testcase\"\n",
        "COL_NAME_ACCURACY = \"Accuracy\"\n",
        "COL_NAME_DURATION = \"Duration\"\n",
        "COL_NAMES = [COL_NAME_METHOD_NAME, COL_NAME_ACCURACY]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8qmfM4404am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class decorator_class\n",
        "class decorator_class(object):\n",
        "\n",
        "    def __init__(self, original_function):\n",
        "        self.original_function = original_function\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        print('call method before {}'.format(self.original_function.__name__))\n",
        "        self.original_function(*args, **kwargs)\n",
        "\n",
        "\n",
        "def logger(original_func):\n",
        "    logging.basicConfig(filename='{}.log'.format(original_func.__name__),\n",
        "                        level=logging.INFO)\n",
        "\n",
        "    @wraps(original_func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        logging.info('Ran with args: {}, and kwargs: {}'.format(args, kwargs))\n",
        "        return original_func(*args, **kwargs)\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "def cls_timer(original_func):\n",
        "    @wraps(original_func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        t1 = time.time()\n",
        "        result = original_func(*args, **kwargs)\n",
        "        t2 = time.time() - t1\n",
        "        print('{} ran in: {} sec'.format(original_func.__name__, round(t2,2)))\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "# class Normalize\n",
        "class Normalize(object):\n",
        "    def normalize(self, X_train, X_test):\n",
        "        self.scaler = MinMaxScaler()\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_test  = self.scaler.transform(X_test)\n",
        "        return (X_train, X_test)\n",
        "\n",
        "    def inverse(self, X_train, X_test):\n",
        "        X_train = self.scaler.inverse_transform(X_train)\n",
        "        X_test  = self.scaler.inverse_transform(X_test)\n",
        "        return (X_train, X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdDcqb8Jggn2",
        "colab_type": "code",
        "outputId": "d87988d0-a8ad-4f86-c7bd-8fbcb4b751da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "# Deep learning Librairies\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaC1mXro1VxS",
        "colab_type": "text"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfVSRewwkx39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class algo_logistic_regression for Machine Learning\n",
        "class algo_logistic_regression(object):\n",
        "\n",
        "    @logger\n",
        "    @cls_timer\n",
        "    def __init__(self, X_train, y_train, X_test, y_test):\n",
        "        self.X_train, self.y_train, self.X_test, self.y_test = X_train, y_train, X_test, y_test\n",
        "\n",
        "    @logger\n",
        "    @cls_timer\n",
        "    def fit(self):\n",
        "        normalizer = Normalize()\n",
        "        self.X_train, self.X_test = normalizer.normalize(self.X_train, self.X_test)\n",
        "        train_samples = self.X_train.shape[0]\n",
        "        self.classifier = LogisticRegression(\n",
        "            C=50. / train_samples,\n",
        "            multi_class='multinomial',\n",
        "            penalty='l1',\n",
        "            solver='saga',\n",
        "            tol=0.1,\n",
        "            class_weight='balanced')\n",
        "        self.classifier.fit(self.X_train, self.y_train)\n",
        "        self.train_y_predicted = self.classifier.predict(self.X_train)\n",
        "        self.train_accuracy = round(np.mean(self.train_y_predicted.ravel() == self.y_train.ravel()) * 100, 2)\n",
        "        self.train_confusion_matrix = confusion_matrix(self.y_train, self.train_y_predicted)\n",
        "\n",
        "        return self.train_accuracy\n",
        "\n",
        "    @logger\n",
        "    @cls_timer\n",
        "    def predict(self):\n",
        "        self.test_y_predicted = self.classifier.predict(self.X_test)\n",
        "        self.test_accuracy = round(np.mean(self.test_y_predicted.ravel() == self.y_test.ravel()) * 100, 2)\n",
        "        self.test_confusion_matrix = confusion_matrix(self.y_test, self.test_y_predicted)\n",
        "        self.report = classification_report(self.y_test, self.test_y_predicted)\n",
        "        print(\"Classification report for classifier Logistic Regression:\\n %s\\n\" % (self.report))\n",
        "        return self.test_accuracy\n",
        "\n",
        "    @logger\n",
        "    @cls_timer\n",
        "    def predict_dummy(self):\n",
        "        \"\"\"Dummy prediction with baseline obtained result between [0,9]\n",
        "        \"\"\"\n",
        "        #self.test_y_predicted_baseline = np.array([str(x) for x in np.random.randint(10, size=len(self.X_test))])\n",
        "        self.test_y_predicted_baseline = np.array([x for x in np.random.randint(10, size=len(self.X_test))])\n",
        "        self.test_accuracy_baseline = round(np.mean(self.test_y_predicted_baseline.ravel() == self.y_test.ravel() * 100), 2)\n",
        "        self.test_confusion_matrix_baseline = confusion_matrix(self.y_test, self.test_y_predicted_baseline)\n",
        "        self.report_baseline = classification_report(self.y_test, self.test_y_predicted_baseline)\n",
        "        print(\"Classification report for classifier - Baseline:\\n %s\\n\" % (self.report_baseline))\n",
        "        return self.test_accuracy_baseline\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50IyeWGA1oJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class algo_multilayer_perceptron for Machine Learning\n",
        "class algo_multilayer_perceptron(object):\n",
        "\n",
        "    @logger\n",
        "    @cls_timer\n",
        "    def __init__(self, X_train, y_train, X_test, y_test):\n",
        "        self.X_train, self.y_train, self.X_test, self.y_test = X_train, y_train, X_test, y_test\n",
        "\n",
        "    @logger\n",
        "    @cls_timer\n",
        "    def fit(self):\n",
        "        normalizer = Normalize()\n",
        "        self.X_train, self.X_test = normalizer.normalize(self.X_train, self.X_test)\n",
        "        train_samples = self.X_train.shape[0]\n",
        "        self.classifier = MLPClassifier(hidden_layer_sizes=(50,), max_iter=10, alpha=1e-4,\n",
        "                                        solver='sgd', verbose=10, random_state=1,\n",
        "                                        learning_rate_init=.1)\n",
        "        self.classifier.fit(self.X_train, self.y_train)\n",
        "        self.train_y_predicted = self.classifier.predict(self.X_train)\n",
        "        self.train_accuracy = round(np.mean(self.train_y_predicted.ravel() == self.y_train.ravel()) * 100, 2)\n",
        "        self.train_confusion_matrix = confusion_matrix(self.y_train, self.train_y_predicted)\n",
        "        return self.train_accuracy\n",
        "\n",
        "    @logger\n",
        "    @cls_timer\n",
        "    def predict(self):\n",
        "        self.test_y_predicted = self.classifier.predict(self.X_test)\n",
        "        self.test_accuracy = round(np.mean(self.test_y_predicted.ravel() == self.y_test.ravel()) * 100, 2)\n",
        "        self.test_confusion_matrix = confusion_matrix(self.y_test, self.test_y_predicted)\n",
        "        self.report = classification_report(self.y_test, self.test_y_predicted)\n",
        "        print(\"Classification report for classifier Logistic Regression:\\n %s\\n\" % (self.report))\n",
        "        return self.test_accuracy\n",
        "\n",
        "    @logger\n",
        "    @cls_timer\n",
        "    def predict_dummy(self):\n",
        "        \"\"\"Dummy prediction with baseline obtained result between [0,9]\n",
        "        \"\"\"\n",
        "        #self.test_y_predicted_baseline = np.array([str(x) for x in np.random.randint(10, size=len(self.X_test))])\n",
        "        self.test_y_predicted_baseline = np.array([x for x in np.random.randint(10, size=len(self.X_test))])\n",
        "        self.test_accuracy_baseline = round(np.mean(self.test_y_predicted_baseline.ravel() == self.y_test.ravel() * 100), 2)\n",
        "        self.test_confusion_matrix_baseline = confusion_matrix(self.y_test, self.test_y_predicted_baseline)\n",
        "        self.report_baseline = classification_report(self.y_test, self.test_y_predicted_baseline)\n",
        "        print(\"Classification report for classifier - Baseline:\\n %s\\n\" % (self.report_baseline))\n",
        "        return self.test_accuracy_baseline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqkokyJql0dT",
        "colab_type": "text"
      },
      "source": [
        "#1. Loading the IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZyhjjmal4Ge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import imdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbNH1ZC-nCTL",
        "colab_type": "code",
        "outputId": "48786098-e361-412c-aa6f-d9b8c669e1a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# split train, test\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000) # 10k top most frequent words"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6r-KhhWnCV9",
        "colab_type": "code",
        "outputId": "4a3d2e3b-8b01-4926-d8b4-735aa6b2d236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_data), len(test_data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNSoOPJKnCZA",
        "colab_type": "code",
        "outputId": "60ccbee3-a078-4dab-8128-ed6c8376c0fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(train_data[0]) \n",
        "print(train_labels[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1hIRmAgnCj0",
        "colab_type": "code",
        "outputId": "a8c246aa-2b73-4ca5-d6cd-76a5944eda8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# word_index is a dictionary mapping words to an integer index\n",
        "word_index = imdb.get_word_index()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 1s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43TbtzoLoU7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reserve_word_index = dict([(val, key) for (key, val) in word_index.items()])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-32SuLcMpoCf",
        "colab_type": "text"
      },
      "source": [
        "Decodes the review. Note that the indices are offset by 3 because 0, 1, and 2 are reserved indices for “padding,” “start of sequence,” and “unknown.”"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb8-I2lDoU_I",
        "colab_type": "code",
        "outputId": "bb8ea8af-e96f-4937-fca3-b425ee1aaa30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "decoded_review = ' '.join([reserve_word_index.get(i-3, '?') for i in train_data[0]])\n",
        "decoded_review"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfdE2k2ep2nz",
        "colab_type": "text"
      },
      "source": [
        "#2. Preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyIko6UkoVEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5le3qDd1oVH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to vectorize a sequence\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "  results = np.zeros((len(sequences), dimension)) # all-zero matrix of shape (x,y)\n",
        "\n",
        "  for i, seq in enumerate(sequences):\n",
        "    results[i, seq] = 1. \n",
        "  \n",
        "  return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxs-i6eEoVLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize trainset, testset\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52dmDsfvoVQW",
        "colab_type": "code",
        "outputId": "dd0fb473-4704-4ef9-fd92-a9799d048dee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x_train[:2]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 1., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "burRPeNJoVTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize the labels\n",
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYx8qx2FoVOd",
        "colab_type": "code",
        "outputId": "7fdf7b42-1ff1-44c7-ed42-06b5d49f50fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:2]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbl_yxvzywJC",
        "colab_type": "text"
      },
      "source": [
        "# Baseline Model with Machine Learning with sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYFuxtcd2MhF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = [] # variable to stock (method_ML, accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bmo7qks0XRM",
        "colab_type": "text"
      },
      "source": [
        "## 1. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzfae4_9zKdF",
        "colab_type": "code",
        "outputId": "6efefaee-99bd-4bb6-8c34-eba5eb47130c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "t0 = time.time()\n",
        "np.random.seed(42)\n",
        "clf_logReg = algo_logistic_regression(x_train, y_train, x_test, y_test)\n",
        "train_acc = clf_logReg.fit()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__init__ ran in: 0.0 sec\n",
            "fit ran in: 25.8 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V1RHLB9zKRe",
        "colab_type": "code",
        "outputId": "99d00364-dba9-48d6-ec82-e983499cb8a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Train accuracy\n",
        "print(\"Train accuracy - baseline: \", train_acc)\n",
        "print(\"Confusion Matrix \\n\", clf_logReg.train_confusion_matrix)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy - baseline:  68.31\n",
            "Confusion Matrix \n",
            " [[7146 5354]\n",
            " [2568 9932]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZspmkQinRMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add to list results\n",
        "method_name = \"Train - Logistic Regression\"\n",
        "results.append((method_name, train_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US6teqDuzKaa",
        "colab_type": "code",
        "outputId": "8722b0e6-7ee2-4eba-8512-63f8297a2c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# Test accuracy\n",
        "test_acc_baseline = clf_logReg.predict()\n",
        "print(\"Test accuracy - baseline: \", test_acc_baseline)\n",
        "print(\"Confusion Matrix \\n\", clf_logReg.test_confusion_matrix)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier Logistic Regression:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.74      0.57      0.64     12500\n",
            "         1.0       0.65      0.80      0.72     12500\n",
            "\n",
            "    accuracy                           0.68     25000\n",
            "   macro avg       0.69      0.68      0.68     25000\n",
            "weighted avg       0.69      0.68      0.68     25000\n",
            "\n",
            "\n",
            "predict ran in: 0.41 sec\n",
            "Test accuracy - baseline:  68.44\n",
            "Confusion Matrix \n",
            " [[ 7111  5389]\n",
            " [ 2500 10000]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OVw6SHinOnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add to list results\n",
        "method_name = \"Test Logistic Regression\"\n",
        "results.append((method_name, test_acc_baseline))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nffEiDXzKXm",
        "colab_type": "code",
        "outputId": "82310fad-a96e-4b8a-a1b3-882ad4a8f371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "results"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Train - Logistic Regression', 68.31), ('Test Logistic Regression', 68.44)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOhiu8I7zKNw",
        "colab_type": "code",
        "outputId": "2ba35cbe-bb4d-483d-b584-ee9b98817438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Sparsity with L1 penalty\n",
        "sparsity = np.mean(clf_logReg.classifier.coef_ ==0)*100\n",
        "print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity)\n",
        "\n",
        "coef = clf_logReg.classifier.coef_.copy()\n",
        "plt.figure(figsize=(10,5))\n",
        "scale = np.abs(coef).max()\n",
        "\n",
        "for i in range(2):\n",
        "  l1_plot = plt.subplot(2, 5, i+1)\n",
        "  # l1_plot.imshow(coef[i].reshape(),      # error\n",
        "  #                interpolation='nearest', \n",
        "  #                cmap=plt.cm.RdBu,\n",
        "  #                vmin=-scale, vmax=scale)\n",
        "  l1_plot.set_xticks(())\n",
        "  l1_plot.set_yticks(())\n",
        "  l1_plot.set_xlabel('Class %i' % i)\n",
        "\n",
        "plt.suptitle(\"Classification vector for LR\")\n",
        "\n",
        "run_time = time.time() - t0\n",
        "print(\"Example run in %.3f sec\" % run_time)\n",
        "plt.show()\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sparsity with L1 penalty: 96.98%\n",
            "Example run in 26.303 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAC7CAYAAAB8QcX8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WefWEvHDj0z3",
        "colab_type": "text"
      },
      "source": [
        "## 2. MLP - MultiLayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PMieJLD99kR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "8c462628-cd00-4268-c101-701707219e65"
      },
      "source": [
        "t0 = time.time()\n",
        "np.random.seed(42)\n",
        "clf_MLP = algo_multilayer_perceptron(x_train, y_train, x_test, y_test)\n",
        "train_acc_MLP = clf_MLP.fit()\n",
        "\n",
        "# Train accuracy\n",
        "print(\"Train accuracy - baseline: \", train_acc_MLP)\n",
        "print(\"Confusion Matrix \\n\", clf_MLP.train_confusion_matrix)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__init__ ran in: 0.0 sec\n",
            "Iteration 1, loss = 0.36977276\n",
            "Iteration 2, loss = 0.24011666\n",
            "Iteration 3, loss = 0.19881995\n",
            "Iteration 4, loss = 0.15541971\n",
            "Iteration 5, loss = 0.12015724\n",
            "Iteration 6, loss = 0.08961149\n",
            "Iteration 7, loss = 0.05399652\n",
            "Iteration 8, loss = 0.03014972\n",
            "Iteration 9, loss = 0.01486434\n",
            "Iteration 10, loss = 0.00814872\n",
            "fit ran in: 54.27 sec\n",
            "Train accuracy - baseline:  100.0\n",
            "Confusion Matrix \n",
            " [[12500     0]\n",
            " [    0 12500]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58U-YdJ9nK3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add to list results\n",
        "method_name = \"Train - MultiLayer Perceptron\"\n",
        "results.append((method_name, train_acc_MLP))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2K1zrAq99hP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "1f1fea13-b4f9-4138-9fdd-1dea3be02936"
      },
      "source": [
        "# Test accuracy\n",
        "test_acc_MLP = clf_MLP.predict()\n",
        "print(\"Test accuracy - baseline: \", test_acc_MLP)\n",
        "print(\"Confusion Matrix \\n\", clf_MLP.test_confusion_matrix)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier Logistic Regression:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.88      0.87     12500\n",
            "         1.0       0.88      0.87      0.87     12500\n",
            "\n",
            "    accuracy                           0.87     25000\n",
            "   macro avg       0.87      0.87      0.87     25000\n",
            "weighted avg       0.87      0.87      0.87     25000\n",
            "\n",
            "\n",
            "predict ran in: 0.95 sec\n",
            "Test accuracy - baseline:  87.2\n",
            "Confusion Matrix \n",
            " [[10974  1526]\n",
            " [ 1674 10826]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_Nx6-t8nIFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add to list results\n",
        "method_name = \"Test MultiLayer Perceptron\"\n",
        "results.append((method_name, test_acc_MLP))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xLU33k899bu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "fe0655c8-9864-4c85-f0fe-636387ff7ccb"
      },
      "source": [
        "results"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Train - Logistic Regression', 68.31),\n",
              " ('Test Logistic Regression', 68.44),\n",
              " ('Train - MultiLayer Perceptron', 100.0),\n",
              " ('Test MultiLayer Perceptron', 87.2)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QQGqiiPpUrV",
        "colab_type": "text"
      },
      "source": [
        "## Unittest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cexApvh699Ya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import unittest\n",
        "\n",
        "class TestInput(unittest.TestCase):\n",
        "  \n",
        "    @classmethod\n",
        "    def setUpClass(cls):\n",
        "        # print('setupClass')   \n",
        "        pass\n",
        "\n",
        "    @classmethod\n",
        "    def tearDownClass(cls): \n",
        "        # print('teardownClass')\n",
        "        pass\n",
        "\n",
        "    def setUp(self):\n",
        "        print('setUp') \n",
        "               \n",
        "        # split train, test\n",
        "        (train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000) # 10k top most frequent words\n",
        "        # vectorize trainset, testset\n",
        "        x_train = vectorize_sequences(train_data)\n",
        "        x_test = vectorize_sequences(test_data)\n",
        "        # vectorize the labels\n",
        "        y_train = np.asarray(train_labels).astype('float32')\n",
        "        y_test = np.asarray(test_labels).astype('float32')\n",
        "        self.X_train, self.y_train, self.X_test, self.y_test = x_train, y_train, x_test, y_test\n",
        "        \n",
        "        self.train_accuracy = 68.31\n",
        "        self.train_confusion_matrix = np.matrix([[7146,    5354],\n",
        "                                                 [2568,   9932]])\n",
        "        \n",
        "        self.test_accuracy = 68.44\n",
        "        self.test_confusion_matrix = np.matrix([[7111,    5389],\n",
        "                                                 [2500,   10000]])\n",
        "\n",
        "        \n",
        "    def tearDown(self):\n",
        "        # print('tearDown')\n",
        "        pass\n",
        "        \n",
        "        \n",
        "    def test_fit(self):     \n",
        "        np.random.seed(42)\n",
        "        self.ta = algo_logistic_regression(self.X_train, self.y_train, self.X_test, self.y_test)\n",
        "        self.assertEqual(self.ta.fit(), self.train_accuracy) \n",
        "        self.assertEqual(self.ta.train_confusion_matrix.tolist(), self.train_confusion_matrix.tolist())  \n",
        "  \n",
        "\n",
        "    def test_predict(self):\n",
        "        np.random.seed(42)\n",
        "        self.ta = algo_logistic_regression(self.X_train, self.y_train, self.X_test, self.y_test)\n",
        "        self.ta.fit()\n",
        "        self.assertEqual(self.ta.predict(), self.test_accuracy)\n",
        "        self.assertEqual(self.ta.train_confusion_matrix.tolist(), self.train_confusion_matrix.tolist()) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f02PbM-o99UB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "c2cdbcd0-106a-4dac-a2b4-95c21b2e7ba6"
      },
      "source": [
        "#run tests \n",
        "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setUp\n",
            "__init__ ran in: 0.0 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "."
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fit ran in: 26.03 sec\n",
            "setUp\n",
            "__init__ ran in: 0.0 sec\n",
            "fit ran in: 24.12 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "."
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier Logistic Regression:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.74      0.57      0.64     12500\n",
            "         1.0       0.65      0.80      0.72     12500\n",
            "\n",
            "    accuracy                           0.68     25000\n",
            "   macro avg       0.69      0.68      0.68     25000\n",
            "weighted avg       0.69      0.68      0.68     25000\n",
            "\n",
            "\n",
            "predict ran in: 0.41 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 65.361s\n",
            "\n",
            "OK\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x7fd86f52d278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIvdJ7ZwrZNh",
        "colab_type": "text"
      },
      "source": [
        "## 3. Building a network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6YWNm40sWid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers, optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_vj8_eSrfMk",
        "colab_type": "code",
        "outputId": "cc6c5246-c2c3-47d1-b5df-b2efe0f4a403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Three layers\n",
        "input_tensor = layers.Input(shape=(10000,))\n",
        "x = layers.Dense(32, activation='tanh')(input_tensor)  \n",
        "x = layers.Dense(32, activation='tanh')(x)             \n",
        "\n",
        "output_tensor = layers.Dense(1, activation='sigmoid')(x)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVsjxZfErf5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Model(inputs=input_tensor, outputs=output_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFke-4azrf_H",
        "colab_type": "code",
        "outputId": "013e820c-436c-4c40-b5b0-b78bc39a7955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()   # summary of the NN architecture"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                320032    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 321,121\n",
            "Trainable params: 321,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEBIqApSrgE5",
        "colab_type": "code",
        "outputId": "eea9d13c-2bc2-4927-c6aa-298a3f2496cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# compile\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "# model.compile(optimizer='rmsprop', loss='mse', metrics=['acc'])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9zxcn04rgNB",
        "colab_type": "code",
        "outputId": "a1d1f8c7-ae0f-4f6c-f03a-ffed8e6ace5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# train a model\n",
        "history = model.fit(x_train, y_train, batch_size=128, epochs=10)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 6s 228us/step - loss: 0.1239 - acc: 0.9716\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 3s 118us/step - loss: 0.0598 - acc: 0.9815\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 3s 111us/step - loss: 0.0406 - acc: 0.9874\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 3s 107us/step - loss: 0.0293 - acc: 0.9909\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 3s 106us/step - loss: 0.0222 - acc: 0.9930\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 3s 107us/step - loss: 0.0168 - acc: 0.9949\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 3s 109us/step - loss: 0.0131 - acc: 0.9962\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 3s 110us/step - loss: 0.0096 - acc: 0.9974\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 3s 109us/step - loss: 0.0073 - acc: 0.9978\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 3s 107us/step - loss: 0.0049 - acc: 0.9987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14cxI3tDvwqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# With LSTM\n",
        "from keras import preprocessing\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "\n",
        "# hyper-parameters\n",
        "max_features = 10000 # number of words to consider as features, 10k most common words\n",
        "maxlen = 20 # cuts off the text after 20 words (among the max_features most common words)\n",
        "\n",
        "# Raw data\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Preprocessing\n",
        "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen) # pad sequences to the same length\n",
        "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen) # pad sequences to the same length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv8wt6gowuQF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "d580526d-4ae1-4964-d432-6d1a32ef3ccd"
      },
      "source": [
        "# Building a network\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_features, output_dim=8, input_length=maxlen))\n",
        "model.add(LSTM(32, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid')) # output layer\n",
        "\n",
        "# compile\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "# summary\n",
        "model.summary()\n",
        "\n",
        "# Training\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.1) # 10% of x_train\n",
        "\n",
        "# Evaluate\n",
        "score, acc = model.evaluate(x_test, y_test)\n",
        "print('test score = ', score)\n",
        "print('test accuracy = ', acc)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 20, 8)             80000     \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 20, 32)            5248      \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 93,601\n",
            "Trainable params: 93,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 22500 samples, validate on 2500 samples\n",
            "Epoch 1/10\n",
            "22500/22500 [==============================] - 23s 1ms/step - loss: 0.5784 - acc: 0.6852 - val_loss: 0.6011 - val_acc: 0.6888\n",
            "Epoch 2/10\n",
            "22500/22500 [==============================] - 22s 960us/step - loss: 0.4599 - acc: 0.7802 - val_loss: 0.4898 - val_acc: 0.7616\n",
            "Epoch 3/10\n",
            "22500/22500 [==============================] - 22s 996us/step - loss: 0.4288 - acc: 0.8012 - val_loss: 0.5152 - val_acc: 0.7584\n",
            "Epoch 4/10\n",
            "22500/22500 [==============================] - 21s 948us/step - loss: 0.4128 - acc: 0.8124 - val_loss: 0.4911 - val_acc: 0.7644\n",
            "Epoch 5/10\n",
            "22500/22500 [==============================] - 21s 953us/step - loss: 0.4009 - acc: 0.8183 - val_loss: 0.5160 - val_acc: 0.7612\n",
            "Epoch 6/10\n",
            "22500/22500 [==============================] - 21s 945us/step - loss: 0.3906 - acc: 0.8257 - val_loss: 0.4850 - val_acc: 0.7680\n",
            "Epoch 7/10\n",
            "22500/22500 [==============================] - 21s 941us/step - loss: 0.3820 - acc: 0.8272 - val_loss: 0.4899 - val_acc: 0.7772\n",
            "Epoch 8/10\n",
            "22500/22500 [==============================] - 22s 967us/step - loss: 0.3755 - acc: 0.8332 - val_loss: 0.4706 - val_acc: 0.7700\n",
            "Epoch 9/10\n",
            "22500/22500 [==============================] - 21s 937us/step - loss: 0.3666 - acc: 0.8368 - val_loss: 0.5176 - val_acc: 0.7744\n",
            "Epoch 10/10\n",
            "22500/22500 [==============================] - 21s 953us/step - loss: 0.3580 - acc: 0.8423 - val_loss: 0.4949 - val_acc: 0.7688\n",
            "25000/25000 [==============================] - 4s 176us/step\n",
            "test score =  0.499865355758667\n",
            "test accuracy =  0.76568\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOhLC-UPrgS1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1c41370-5168-44c5-8f63-476f648ef160"
      },
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yMZnY2brgZ9",
        "colab_type": "code",
        "outputId": "70603bdd-d5e9-4747-8749-b74879c00c42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "history.history"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc': [0.971600000038147,\n",
              "  0.981520000038147,\n",
              "  0.9874400000190735,\n",
              "  0.99088,\n",
              "  0.99304,\n",
              "  0.99488,\n",
              "  0.9962,\n",
              "  0.99744,\n",
              "  0.99784,\n",
              "  0.99872],\n",
              " 'loss': [0.1238527124261856,\n",
              "  0.05982205800533295,\n",
              "  0.04059185327649117,\n",
              "  0.02931500919409096,\n",
              "  0.02220388704650104,\n",
              "  0.016783954836502673,\n",
              "  0.01305174713626504,\n",
              "  0.009591524589210748,\n",
              "  0.007290254154801369,\n",
              "  0.004923677662909031]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chJlz8Bkrgdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Draw a graphic\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B31iz_v1rgQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# without validation set\n",
        "loss_value = history_dict['loss']\n",
        "acc_value = history_dict['acc']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P-_wlPQqJWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add to list results\n",
        "method_name = \"Train Recurrent Neural Network\"\n",
        "results.append((method_name, max(acc_value)*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFNGSpuOrgI6",
        "colab_type": "code",
        "outputId": "e61bc800-21f6-49f2-83da-de41ba265649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(epochs, loss_value,'bo', label='Training loss')    # bo: blue dot\n",
        "# plt.plot(epochs, val_loss_value,'y', label='Validation loss')    # bo: blue dot\n",
        "plt.plot(epochs, acc_value, 'b', label='Training Accuracy')          # 'b': solid blue line\n",
        "# plt.plot(epochs, val_acc_value, 'r', label='Validation Accuracy')          # 'b': solid blue line\n",
        "plt.title('Training and validation loss/accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nicDMLOecCMzMcs6JwMws5/4/6Tv7mKH4INsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzAnFapZzfLd",
        "colab_type": "code",
        "outputId": "c63c80ea-9f94-4259-e6b6-b798c7956b23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "# draw model \n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png', show_shapes=True)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAGVCAIAAACw0lsWAAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r920Ss7hysuJ",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKqHQIWFyrz2",
        "colab_type": "code",
        "outputId": "ed9af3ac-7ce7-486e-94e9-c2ed31c6b666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "resultsNN = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 4s 160us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjVsZvvZltEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add to list results\n",
        "method_name = \"Test Recurrent Neural Network\"\n",
        "results.append((method_name, resultsNN[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpikOyaXyruj",
        "colab_type": "code",
        "outputId": "982b5a81-468b-410e-8687-40f35958d53c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# predict\n",
        "model.predict(x_test)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.7759671e-03],\n",
              "       [9.9999857e-01],\n",
              "       [9.9999648e-01],\n",
              "       ...,\n",
              "       [5.2705407e-04],\n",
              "       [2.0641088e-04],\n",
              "       [6.5531462e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn94kun-zPa6",
        "colab_type": "text"
      },
      "source": [
        "# Comparison of multiple models [baseline versus models]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUeFrL4kyrxL",
        "colab_type": "code",
        "outputId": "976e27bf-f609-4095-aa22-c20d9c406f53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "results"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Train - Logistic Regression', 68.31),\n",
              " ('Test Logistic Regression', 68.44),\n",
              " ('Train - MultiLayer Perceptron', 100.0),\n",
              " ('Test MultiLayer Perceptron', 87.2),\n",
              " ('Train Recurrent Neural Network', 99.872),\n",
              " ('Test Recurrent Neural Network', 83.76)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4gURks0yrr8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "35aa8f9a-55a1-404a-bff1-bda07d54868a"
      },
      "source": [
        "df = pd.DataFrame(columns=COL_NAMES, data=results)\n",
        "df"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Testcase</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Train - Logistic Regression</td>\n",
              "      <td>68.310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Test Logistic Regression</td>\n",
              "      <td>68.440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Train - MultiLayer Perceptron</td>\n",
              "      <td>100.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Test MultiLayer Perceptron</td>\n",
              "      <td>87.200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Train Recurrent Neural Network</td>\n",
              "      <td>99.872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Test Recurrent Neural Network</td>\n",
              "      <td>83.760</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Testcase  Accuracy\n",
              "0     Train - Logistic Regression    68.310\n",
              "1        Test Logistic Regression    68.440\n",
              "2   Train - MultiLayer Perceptron   100.000\n",
              "3      Test MultiLayer Perceptron    87.200\n",
              "4  Train Recurrent Neural Network    99.872\n",
              "5   Test Recurrent Neural Network    83.760"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw88IFETo17d",
        "colab_type": "text"
      },
      "source": [
        "In above result, we observe that the accuracy score of method MLP is the best one and it is higher than MLP's accuracy score about 3%.\n",
        "\n",
        "In summary, in this notebook, we performed:\n",
        "\n",
        "* How to train a baseline model versus multiple models\n",
        "\n",
        "* How to use unit tests for the API, the model and the logging\n",
        "\n",
        "* Can all of the unit tests be run with a single script and do all of the unit tests pass?\n",
        "\n",
        "* A mechanism to monitor performance\n",
        "\n",
        "* A performance comparison between multiple models\n",
        "\n",
        "* Visualizations for the EDA investigation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8pZmoPd53ud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}